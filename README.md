import streamlit as st
from PIL import Image
from aisam_utils import print_messages, StreamHandler
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import openai
from openai import OpenAI
import os

import whisper
import sounddevice as sd
import wavio
import time
import random  #ìˆ˜ê°•ìƒ idì˜ valueë¥¼ randomìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆê²Œ í•¨

# Streamlit ì•±ì˜ ì²« ë²ˆì§¸ ëª…ë ¹ìœ¼ë¡œ set_page_config()ë¥¼ í•œ ë²ˆë§Œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
# ì´ë¯¸ ë‹¤ë¥¸ ê³³ì—ì„œ set_page_config()ë¥¼ í˜¸ì¶œí–ˆë‹¤ë©´, ê·¸ ë¶€ë¶„ì„ ì œê±°í•˜ê±°ë‚˜ ì´ ì½”ë“œë¥¼ ê·¸ ë¶€ë¶„ìœ¼ë¡œ ì˜®ê²¨ì£¼ì„¸ìš”.
# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")

# ì´ë¯¸ì§€ ë¡œë“œ
image = Image.open('heeja3.png')

# ì´ë¯¸ì§€ì™€ ì œëª© í‘œì‹œë¥¼ ìœ„í•œ ì»¬ëŸ¼ ìƒì„±
col1, col2 = st.columns([1, 3])  # ë¹„ìœ¨ì„ ì¡°ì •í•˜ì—¬ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ë ˆì´ì•„ì›ƒì„ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
with col1:
    st.image(image, width=80)
with col2:
    st.title("ğŸ‘¨â€ğŸ«ì„±ì°°ê³¼ ë¬¸í•´ë ¥, aií›ˆì¥ìƒ˜ì—ì„œ ì°¾ë‹¤ğŸ‘¨â€ğŸ«")
# í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜ ì¶”ê°€
with st.expander("aií›ˆì¥ìƒ˜ì€ìš”"):
    st.markdown("# ë„ˆëŠ” ì—¬ì „íˆ ë…¼ì–´ë¥¼ ë²ˆì—­ì„œë¡œ ë³´ë‹ˆ?")
    st.markdown("# ë‚œ ì›ë¬¸ìœ¼ë¡œ ì½ëŠ”ë‹¤!")
    #st.set_page_config(page_title="aií›ˆì¥ìƒ˜", page_icon="ğŸ‘¨â€ğŸ«")
    # st.subheader("ğŸ‘¨â€ğŸ« ì„±ì°°ê³¼ ë¬¸í•´ë ¥, ê³ ì „ì—ì„œ ì°¾ë‹¤ ğŸ¤–")
    st.markdown('###ğŸ¤–aií›ˆì¥ìƒ˜ì€ ê³ ì „ì„ ë³´ë‹¤ ì‰½ê³  ì¦ê²ê²Œ ë°°ìš¸ ìˆ˜ ìˆê²Œ ì§€ì›í•©ë‹ˆë‹¤.')

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("base")

# ë¡œì»¬ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì§€ì •
#audio_file = "introduction.mp3"
video_file = "heeja_video.mp4"

# ì¸ì‚¬ ë²„íŠ¼ í´ë¦­ ì‹œ mp3 íŒŒì¼ ì¬ìƒ
if st.button('ì¸ì‚¬'):
    video_file = os.path.join(os.getcwd(), 'heeja_video.mp4')  # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    video_bytes = open(video_file, 'rb').read()
    st.video(video_bytes, format='video/mp4')

# API ì´ˆê¸°í™”
def init_api():
    with open("chatgpt.env") as env:
      for line in env:
        key, value = line.strip().split("=")
        os.environ[key] = value

init_api()

# OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key=os.environ.get("API_KEY"))

# ì˜¤ë””ì˜¤ ë…¹ìŒ ì„¤ì •
duration = 10  # ì´ˆ
fs = 44100  # ìƒ˜í”Œ ë ˆì´íŠ¸

# íŒŒì¼ ê²½ë¡œ
audio_file2 = "recording.mp3"

# ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ëŠ” í•¨ìˆ˜
def record_audio(duration, fs, file_path):
    st.info("ë…¹ìŒ ì¤‘...")
    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2)

    # ë…¹ìŒ ì§„í–‰ ìƒí™©ì„ í‘œì‹œ
    progress_bar = st.progress(0)
    for i in range(duration):
        time.sleep(1)
        progress_bar.progress((i + 1) / duration)
    
    sd.wait()  # ë…¹ìŒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
    wavio.write(file_path, recording, fs, sampwidth=2)
    st.success("ë…¹ìŒ ì™„ë£Œ!")

# ê³„ì„ í¸ ë²„íŠ¼ í´ë¦­ ì‹œ ì˜¤ë””ì˜¤ ë…¹ìŒ ë° í™•ì¸ ë©”ì‹œì§€ ì¶œë ¥
if st.button('ê³„ì„ í¸ì„ ì½ì–´ì£¼ì„¸ìš”.'):
    record_audio(duration, fs, audio_file2)
    st.write("ì˜ ì½ìœ¼ì…¨ìŠµë‹ˆë‹¤.")

# Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ ë¬¸ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def transcribe_audio(file_path):
    st.info("ë³€í™˜ ì¤‘...")
    result = model.transcribe(file_path)
    st.success("ë³€í™˜ ì™„ë£Œ!")
    return result["text"]

if st.button("í•™ìŠµì ì½ì€ ë‚´ìš©"):
    transcription = transcribe_audio(audio_file2)
    st.text_area("ìŒë… ê²°ê³¼", transcription)

if st.button("ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í•œìë¥¼ ë³¼ ìˆ˜ ìˆì–´ìš”"):
    st.write('å­æ›°, çˆ²å–„å­ëŠ” å¤©å ±ä¹‹ä»¥ç¦í•˜ê³  çˆ²ä¸å–„å­ëŠ” å¤©å ±ä¹‹ä»¥ç¦ë‹ˆë¼, ì…ë‹ˆë‹¤.')

button = st.button('í•´ì„ì…ë‹ˆë‹¤.')
if button:
    st.markdown('''
        å­æ›°, çˆ²å–„å­ëŠ” å¤©å ±ä¹‹ä»¥ç¦í•˜ê³  çˆ²ä¸å–„å­ëŠ” å¤©å ±ä¹‹ä»¥ç¦ë‹ˆë¼
        :blue[ê³µìê»˜ì„œ ë§ì”€í•˜ì‹œê¸¸, 
        ì„ í•œ ì¼ì„ í•˜ëŠ” ì‚¬ëŒì€ í•˜ëŠ˜ì´ ë³µìœ¼ë¡œì¨ ë‹µí•˜ê³  
        ì„ ì„ í–‰í•˜ì§€ ì•ŠëŠ” ìëŠ” í•˜ëŠ˜ì´ ì¬ì•™ìœ¼ë¡œì¨ ë‹µí•˜ë‹ˆë¼.]
        ''')

# AI ëŒ€í™” ê¸°ëŠ¥
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì±„íŒ… ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state["store"] = dict()

with st.sidebar:
    session_id = st.text_input("ìˆ˜ê°•ìƒ ID", value=str(random.randint(1,10000)))  # ëŒ€í™”ë°©ì˜ ì•„ì´ë””

    clear_btn = st.button("ìˆ˜ê°•ìƒ í•™ìŠµê¸°ë¡ ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state["messages"] = []
        # st.session_state["store"] = dict()  ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”
        st.experimental_rerun()

# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ ì£¼ëŠ” ì½”ë“œ
print_messages()

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids: str) -> BaseChatMessageHistory:
    # ì£¼ì–´ì§„ user_idì™€ conversation_idì— í•´ë‹¹í•˜ëŠ” ì„¸ì…˜ ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    if session_ids not in st.session_state["store"]:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
        # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥
        st.session_state["store"][session_ids] = ChatMessageHistory()
    return st.session_state["store"][session_ids]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”"):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))
    
    # AIì˜ ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())

        # LLMì„ ì‚¬ìš©í•˜ì—¬ AIì˜ ë‹µë³€ì„ ìƒì„±
        llm = ChatOpenAI(openai_api_key=os.environ.get("API_KEY"), 
                         streaming=True, callbacks=[stream_handler])

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "ë„ˆëŠ” í•œë¬¸ì„ ë§ì´ ì•Œê³  ìˆëŠ” ë™ì–‘ì² í•™ êµìˆ˜ì•¼. ì§ˆë¬¸ì— ê°„ê²°í•˜ë©´ì„œë„ ë”°ëœ»í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”"),
                MessagesPlaceholder(variable_name="history"),  # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©
                ("human", "{question}"),  # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì…ë ¥
            ]
        )

        chain = prompt | llm

        chain_with_memory = RunnableWithMessageHistory(
            chain,  # ì‹¤í–‰í•  Runnable ê°ì²´
            get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
            input_messages_key="question",  # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
            history_messages_key="history",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤
        )

        response = chain_with_memory.invoke(
            {"question": user_input},
            config={"configurable": {"session_id": session_id}},  # ì„¸ì…˜ID ì„¤ì •
        )

    st.session_state["messages"].append(
        ChatMessage(role="assistant", content=response.content)
    )
